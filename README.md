# 번역 서비스 웹 애플리케이션
Flask를 이용한 번역 서비스 웹 애플리케이션입니다

<img width="1711" height="1228" alt="image" src="https://github.com/user-attachments/assets/053144d0-d2fb-4546-85b9-bff13f411acb" />

업로드 화면<br><br>
  
<img width="1369" height="1247" alt="image" src="https://github.com/user-attachments/assets/baebd883-fc0d-4e15-97b8-df84d79d2e68" />
진행화면

## 기능

- 텍스트 번역 (여러 언어 지원)
- 다중 SRT 파일 번역 및 다운로드
- 사용자 친화적인 인터페이스
- Google API 키 및 모델명 설정 가능
- 실시간 번역 진행 상황 표시
- 컨텍스트 압축/토큰 제한을 통한 장문 번역 지원
- 번역 완료 후 대화 히스토리를 JSON 로그로 자동 보관
- **YouTube 링크 맥락 분석**: 번역 청크마다 최소 1장의 스냅샷(10개 엔트리당 1장 추가)을 추출해 모델이 장면을 이해하도록 보조 (이미지와 번역 요청을 한 번에 전송)
- **Thinking Budget 설정**: 숫자 입력 또는 `auto`로 Gemini의 사고 과정 토큰 예산 제어
- **프리셋 관리**: 자주 사용하는 번역 설정을 저장하고 불러오기

## 자막 생성 파이프라인

이 프로젝트는 긴 영상을 다음과 같은 순서로 처리해 자막을 만듭니다.

1. **영상 분할**: 영상을 일정 길이로 나누고 Silero VAD로 각 조각 안의 발화 구간을 표시합니다.
2. **Whisper 보조 전사**: 분할된 조각을 Whisper에 통과시켜 “시작·종료 시각 + 대략적인 문장”을 얻습니다. 이 정보는 다음 단계의 힌트로만 사용합니다.
3. **LLM 정밀 전사/번역**: 조각 영상과 Whisper가 준 힌트를 함께 Gemini에 전달해, 실제 음성을 들은 뒤 더 정확한 문장(또는 번역)을 JSON으로 돌려받습니다.
4. **SRT 저장**: LLM이 돌려준 문장을 전체 타임라인 순으로 정렬해 표준 SRT 파일로 저장합니다.

덕분에 Whisper가 빠르게 타임스탬프를 제시하고, LLM이 의미와 문장을 다듬으면서 자막 품질을 확보할 수 있습니다.

## 사용 팁

- 업로드 폼에서 컨텍스트 압축을 켜고 토큰 한도를 지정하면 히스토리가 자동 요약됩니다.
- 번역이 끝나면 `logs/` 디렉터리에 `history_<job_id>_*.json` 파일이 생성되어 대화 내역을 확인할 수 있습니다.
- 진행 화면의 ZIP 다운로드 버튼으로 여러 파일의 번역본을 한 번에 저장할 수 있습니다.
- YouTube 링크를 입력하면 각 번역 청크마다 스냅샷을 첨부한 채 바로 번역을 요청하여 모델이 장면 정보를 참고합니다(엔트리 10개마다 스냅샷 1장 추가; 컨텍스트 압축이 실행되면 오래된 이미지 참조는 자동 정리).
- 생성된 스냅샷 파일은 `snapshots/` 폴더 아래에 작업/청크별로 저장되니, 번역 후에도 그대로 열람할 수 있습니다.

- **Thinking Budget 설정**:
  - 숫자 입력 (예: `512`, `1024`, `2048`): 해당 토큰 수만큼 사고 과정 예산 설정
  - `auto`: Gemini가 자동으로 최적의 예산을 결정
  - 비활성화 체크박스: Thinking 기능 완전 비활성화
- 자주 사용하는 설정은 프리셋으로 저장하여 빠르게 재사용할 수 있습니다.

## 설치 방법

### 원클릭 설치&실행

1. 프로젝트를 clone 혹은 코드를 다운로드 받은 후 `install_app.bat` 파일 실행 → 가상환경 세팅 후 프로젝트 실행.

2. 설치 완료 후에는 `start_app.bat`으로 실행.

### 수동 설치 가이드

1. 가상환경 생성:
  ```bash
  python -m venv .venv
  ```

2. 가상환경 활성화:
  ```bash
  .venv\Scripts\activate
  ```

3. 의존성 설치:
  ```bash
  pip install -r requirements.txt
  ```

4. 애플리케이션 실행:
  ```bash
  python app.py
  ```

5. 웹 브라우저에서 애플리케이션 접속:
  ```
  http://127.0.0.1:5000
  ```

## 개발 환경

- Flask 3.0.2
- Google Generative AI SDK

## 주요 파일 구조

```
project/
├── app.py                # Flask 애플리케이션 엔트리 포인트
├── requirements.txt      # Python 의존성 목록
├── module/               # 주요 기능 모듈
│   ├── database_module.py
│   ├── ffmpeg_module.py
│   ├── gemini_module.py
│   └── srt_module.py
├── static/               # 정적 파일 (CSS, JS)
│   ├── css/
│   └── js/
└── templates/            # HTML 템플릿
```

## 사용 방법

1. **API 키 설정**: 우측 상단 "추가 설정" 버튼을 클릭하여 Google API 키를 입력하고 저장
2. **번역 설정**:
   - 타겟 언어: 번역할 언어 지정 (예: 한국어, English)
   - 청크 크기: 한 번에 번역할 자막 수
   - Thinking Budget: `auto`, `512`, `1024`, `2048` 등 선택 또는 직접 입력
   - 커스텀 프롬프트: 번역 스타일 또는 추가 지시사항 입력
3. **SRT 파일 업로드**: 드래그 앤 드롭 또는 파일 선택
4. **번역 시작**: "번역 시작하기" 버튼 클릭
5. **진행 상황 확인**: 실시간으로 번역 진행 상황 모니터링
6. **결과 다운로드**: 개별 파일 다운로드 또는 ZIP으로 일괄 다운로드

### 프리셋 관리
- 자주 사용하는 번역 설정을 프리셋으로 저장
- 프리셋 선택 시 저장된 설정 자동 적용
- "저장" 버튼으로 현재 프리셋 업데이트
- "새로 만들기" 버튼으로 새 프리셋 생성
